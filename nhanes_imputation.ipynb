{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis with missing data in Python Statsmodels, a case study with the NHANES data\n",
    "\n",
    "This notebook demonstrates several techniques for working with missing data in Python,\n",
    "using the Statsmodels library.  The methods are presented through a series of illustrations\n",
    "using data from the NHANES (National Health and Nutrition Examination Study).\n",
    "\n",
    "First we import the libraries that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the cells below require the Github master version of statsmodels.  You\n",
    "# should delete the following cells and install Statsmodels from the github master\n",
    "# if you want to run the full notebook.\n",
    "import sys\n",
    "sys.path.insert(0, \"/afs/umich.edu/user/k/s/kshedden/statsmodels_fork/statsmodels\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from statsmodels.imputation import mice\n",
    "from statsmodels.imputation.bayes_mi import BayesGaussMI, MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the data.  The NHANES study encompasses multiple\n",
    "waves of data collection.  Here we will only use the 2015-2016 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/kshedden/statswpy/master/NHANES/merged/nhanes_2015_2016.csv\"\n",
    "da = pd.read_csv(url)\n",
    "\n",
    "# Retain a subset of columns for use below.\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\", \"SMQ020\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple imputation\n",
    "\n",
    "Here we demonstrate how to use multiple imputation to estimate a correlation\n",
    "coefficient when some data values are missing.\n",
    "Blood pressure and BMI are expected to be positively related, and we estimate\n",
    "the correlation between them below.  A deep understanding\n",
    "of the relationship between blood pressure and BMI should control for gender, BMI,\n",
    "and other relevant factors.  But for illustration, we focus here on the simple\n",
    "unadjusted correlation.\n",
    "\n",
    "In the next cell, we determine how many values of these variables are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = da.loc[:, [\"BPXSY1\", \"BMXBMI\"]]\n",
    "print(dx.shape)\n",
    "print(pd.isnull(dx).sum(0))\n",
    "print(pd.isnull(dx).prod(1).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for comparison purposes, we estimate the correlation coefficient\n",
    "and its standard error using \"complete case\" analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dx.dropna()\n",
    "c = np.cov(dd.T)\n",
    "\n",
    "r_cc = c[0, 1] / np.sqrt(c[0, 0] * c[1, 1])\n",
    "print(\"Complete case estimate:       %f\" % r_cc)\n",
    "print(\"Complete case standard error: %f\\n\" % (1 / np.sqrt(dd.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use multiple imputation.  Statsmodels provides a\n",
    "Bayesian imputation framework using the Gaussian distribution (we will\n",
    "explore other ways to do imputation later).\n",
    "\n",
    "Like most Bayesian methods, this approach utilizes prior distributions\n",
    "on the structural parameters of the model.  If the data are approximately\n",
    "standardized (i.e. have zero mean and unit variance), then the default\n",
    "priors should work fine.  But BMI and blood pressure are measured on scales\n",
    "with values ranging from around 10 to 200.  Therefore, we scale the prior\n",
    "covariance matrices accordingly.\n",
    "\n",
    "To use this approach, we first construct an imputation object and \"burn\"\n",
    "it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = BayesGaussMI(dx, mean_prior=100*np.eye(2), cov_prior=100*np.eye(2))\n",
    "\n",
    "for k in range(100):\n",
    "    bm.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to draw samples from the imputation object, and use\n",
    "these samples to estimate the unknown parameter of interest (the correlation\n",
    "between blood pressure and BMI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = []\n",
    "for k in range(200):\n",
    "    bm.update()\n",
    "\n",
    "    # After calling bm.update, we can access bm.mean and bm.cov,\n",
    "    # which are draws from the posterior distribution of the\n",
    "    # Gaussian mean and covariance parameters given the data.\n",
    "    # We can also access the underlying data frame dx, which\n",
    "    # has now been imputed so that there are no missing values.\n",
    "    r = bm.cov[0, 1] / np.sqrt(bm.cov[0, 0] * bm.cov[1, 1])\n",
    "\n",
    "    rv.append(r)\n",
    "\n",
    "rv = np.asarray(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these posterior samples, we can estimate the posterior mean and\n",
    "posterior variance of the correlation coefficient between BMI and\n",
    "blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: \", rv.mean())\n",
    "print(\"SD:   \", rv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the histogram of the draws from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(rv, bins=15, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study to assess \"information\" in partially observed observations\n",
    "\n",
    "Next we use a small simulation study to better understand the performance characteristics\n",
    "of this type of multiple imputation.  We take the NHANES data for BMI and blood and\n",
    "introduce increasingly greater fractions of missing values into the data.  Then we use\n",
    "multiple imputation (MI) and complete case analysis to estimate the correlation coefficient\n",
    "between blood pressure and BMI, and the standard error of this statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in 0.1, 0.2, 0.4:\n",
    "\n",
    "\tdy = dx.copy()\n",
    "\tfor j in 0, 1:\n",
    "\t\tii = np.flatnonzero(np.random.uniform(size=dy.shape[0]) < f)\n",
    "\t\tdy.iloc[ii, j] = np.nan\n",
    "\n",
    "\t# Complete cases\n",
    "\tdc = dy.dropna()\n",
    "\n",
    "\tbm = BayesGaussMI(dy, mean_prior=100*np.eye(2), cov_prior=100*np.eye(2))\n",
    "\n",
    "\tfor k in range(100):\n",
    "\t    bm.update()\n",
    "\n",
    "\trv = []\n",
    "\tfor k in range(200):\n",
    "\t    bm.update()\n",
    "\t    r = bm.cov[0, 1] / np.sqrt(bm.cov[0, 0] * bm.cov[1, 1])\n",
    "\t    rv.append(r)\n",
    "\trv = np.asarray(rv)\n",
    "\n",
    "\tprint(rv.mean(), rv.std(), 1/np.sqrt(dc.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of any imputation analysis is to recover information from \"partially observed\"\n",
    "cases.  Here, a partially observed case is a person for whom either the blood pressure\n",
    "or BMI value (but not both) is missing.  Depending on the specific statistic that is\n",
    "being calculated (or model that is being fit), the benefit of recovering information\n",
    "from partially observed observations can be substantial, or quite small.\n",
    "\n",
    "Since the missing data values are introduced into random locations, and the MI procedure\n",
    "is itself stochastic, the results of this simulation study will vary from run to run.  In\n",
    "general, the complete case standard error and MI \"standard error\" (which is actually a\n",
    "posterior standard deviation) are quite similar, but the complete case standard error tends\n",
    "to be the slightly larger of the two.  In this setting, the observations with only one value contribute to the MI\n",
    "analysis but not to the complete case analysis.  It turns out that retaining these cases\n",
    "only provides a small amount of information that is relevant for estimating the correlation\n",
    "coefficient.\n",
    "\n",
    "## Multiple imputation for regression\n",
    "\n",
    "The MI class can automate the process of applying multiple imputation to a dataset\n",
    "and using the \"combining rules\" to produce a single set of parameter estimates and standard\n",
    "errors.  We will illustrate this for the task of using linear regression to explore\n",
    "the conditional relationship of blood pressure given BMI, age, and gender.\n",
    "\n",
    "First, we subset the data that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = da.loc[:, [\"BPXSY1\", \"BMXBMI\", \"RIDAGEYR\", \"RIAGENDR\"]]\n",
    "\n",
    "print(dx.shape)\n",
    "print(pd.isnull(dx).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a handful of values are missing, so for illustration purposes, we\n",
    "introduce additional missing values into the age and BMI variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.flatnonzero(np.random.uniform(size=dx.shape[0]) < 0.1)\n",
    "dx.loc[ii, \"RIDAGEYR\"] = np.nan\n",
    "\n",
    "ii = np.random.uniform(size=dx.shape[0]) < 0.1\n",
    "dx.loc[ii, \"BMXBMI\"] = np.nan\n",
    "\n",
    "print(pd.isnull(dx).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.r_[100, 30, 40, 1]\n",
    "bm = BayesGaussMI(dx, mean_prior=np.diag(v), cov_prior=np.diag(v))\n",
    "\n",
    "def model_kwds_fn(x):\n",
    "    return {\"data\": x}\n",
    "\n",
    "mi = MI(bm, sm.OLS, formula=\"BPXSY1 ~ BMXBMI + RIDAGEYR + RIAGENDR\",\n",
    "        burn=0, model_kwds_fn=model_kwds_fn)\n",
    "mir = mi.fit()\n",
    "\n",
    "print(mir.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the multiple imputation results show the full sample size, indicating\n",
    "that no cases were dropped (as in a complete case analysis).\n",
    "\n",
    "# MICE\n",
    "\n",
    "Multiple Imputation with Chained Equations (MICE) is a regression-based framework for imputing missing values\n",
    "that allows us to specify arbitrary regression models for imputing each variable's missing\n",
    "values from the other variables.\n",
    "\n",
    "One common workflow with MICE is to create a set of imputed datasets, then save them as files.\n",
    "They can then be retrieved later and used in an MI analysis using the \"combining rules\".  This\n",
    "workflow is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = da.copy()\n",
    "dx = dx.loc[:, [\"BMXBMI\", \"BPXSY1\", \"RIAGENDR\", \"RIDAGEYR\"]]\n",
    "\n",
    "# Recode to 0 (male), 1 (female)\n",
    "dx.RIAGENDR -= 1\n",
    "\n",
    "for k in range(dx.shape[1]):\n",
    "    ii = np.flatnonzero(np.random.uniform(size=dx.shape[0]) < 0.1)\n",
    "    dx.iloc[ii, k] = np.nan\n",
    "\n",
    "imp_data = mice.MICEData(dx)\n",
    "imp_data.set_imputer(\"BMXBMI\", \"RIDAGEYR + RIAGENDR\")\n",
    "imp_data.set_imputer(\"RIAGENDR\", \"BPXSY1 + RIDAGEYR + BMXBMI\", model_class=sm.GLM,\n",
    "                     init_kwds={\"family\": sm.families.Binomial()})\n",
    "\n",
    "for j in range(10):\n",
    "    imp_data.update_all()\n",
    "\n",
    "    # Uncomment this line to save the files.\n",
    "    #imp_data.to_csv('data%02d.csv' % j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common workflow is to combine the data imputation, modeling and results\n",
    "combination together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = da.copy()\n",
    "dx = dx.loc[:, [\"BMXBMI\", \"BPXSY1\", \"RIAGENDR\", \"RIDAGEYR\"]]\n",
    "\n",
    "# Recode to 0 (male), 1 (female)\n",
    "dx.RIAGENDR -= 1\n",
    "\n",
    "for k in range(dx.shape[1]):\n",
    "    ii = np.flatnonzero(np.random.uniform(size=dx.shape[0]) < 0.1)\n",
    "    dx.iloc[ii, k] = np.nan\n",
    "\n",
    "imp_data = mice.MICEData(dx)\n",
    "imp_data.set_imputer(\"BMXBMI\", \"RIDAGEYR + RIAGENDR\")\n",
    "imp_data.set_imputer(\"RIAGENDR\", \"BPXSY1 + RIDAGEYR + BMXBMI\", model_class=sm.GLM,\n",
    "                     init_kwds={\"families\": sm.families.Binomial()})\n",
    "\n",
    "mi = mice.MICE(\"BPXSY1 ~ RIDAGEYR + RIAGENDR + BMXBMI\", sm.OLS, imp_data, n_skip=1)\n",
    "result = mi.fit(10, 10)\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
